{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the Libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the Dataset\n",
    "dataset=pd.read_csv(\"CKD.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert categorical(nominal or ordinal) data into numerical data and delete first column\n",
    "dataset=pd.get_dummies(dataset,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'bp', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hrmo', 'pcv',\n",
       "       'wc', 'rc', 'sg_b', 'sg_c', 'sg_d', 'sg_e', 'rbc_normal', 'pc_normal',\n",
       "       'pcc_present', 'ba_present', 'htn_yes', 'dm_yes', 'cad_yes',\n",
       "       'appet_yes', 'pe_yes', 'ane_yes', 'classification_yes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset['classification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent=dataset[['age', 'bp', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hrmo', 'pcv',\n",
    "       'wc', 'rc', 'sg_b', 'sg_c', 'sg_d', 'sg_e', 'rbc_normal', 'pc_normal',\n",
    "       'pcc_present', 'ba_present', 'htn_yes', 'dm_yes', 'cad_yes',\n",
    "       'appet_yes', 'pe_yes', 'ane_yes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent=dataset[['classification_yes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(independent,dependent,test_size=1/3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bu</th>\n",
       "      <th>sc</th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>hrmo</th>\n",
       "      <th>...</th>\n",
       "      <th>rbc_normal</th>\n",
       "      <th>pc_normal</th>\n",
       "      <th>pcc_present</th>\n",
       "      <th>ba_present</th>\n",
       "      <th>htn_yes</th>\n",
       "      <th>dm_yes</th>\n",
       "      <th>cad_yes</th>\n",
       "      <th>appet_yes</th>\n",
       "      <th>pe_yes</th>\n",
       "      <th>ane_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>46.370734</td>\n",
       "      <td>70.508421</td>\n",
       "      <td>0.683843</td>\n",
       "      <td>0.364096</td>\n",
       "      <td>100.650236</td>\n",
       "      <td>47.248980</td>\n",
       "      <td>0.955193</td>\n",
       "      <td>141.579608</td>\n",
       "      <td>3.983452</td>\n",
       "      <td>14.947923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.610751</td>\n",
       "      <td>0.489448</td>\n",
       "      <td>0.342997</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.739264</td>\n",
       "      <td>0.739264</td>\n",
       "      <td>0.29277</td>\n",
       "      <td>0.483602</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.445195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>309</td>\n",
       "      <td>65.145665</td>\n",
       "      <td>88.969977</td>\n",
       "      <td>1.059716</td>\n",
       "      <td>0.364096</td>\n",
       "      <td>152.955521</td>\n",
       "      <td>75.699115</td>\n",
       "      <td>3.283622</td>\n",
       "      <td>137.532928</td>\n",
       "      <td>4.604140</td>\n",
       "      <td>12.501720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.610751</td>\n",
       "      <td>0.489448</td>\n",
       "      <td>0.342997</td>\n",
       "      <td>-3.242641</td>\n",
       "      <td>0.739264</td>\n",
       "      <td>0.739264</td>\n",
       "      <td>0.29277</td>\n",
       "      <td>1.936492</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.445195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>334</td>\n",
       "      <td>67.961905</td>\n",
       "      <td>70.508421</td>\n",
       "      <td>0.683843</td>\n",
       "      <td>0.364096</td>\n",
       "      <td>83.873070</td>\n",
       "      <td>42.343784</td>\n",
       "      <td>1.537300</td>\n",
       "      <td>138.864472</td>\n",
       "      <td>4.093577</td>\n",
       "      <td>14.821890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.610751</td>\n",
       "      <td>0.489448</td>\n",
       "      <td>0.342997</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.739264</td>\n",
       "      <td>0.739264</td>\n",
       "      <td>0.29277</td>\n",
       "      <td>0.483602</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.445195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>54.819453</td>\n",
       "      <td>98.200756</td>\n",
       "      <td>0.871779</td>\n",
       "      <td>0.328695</td>\n",
       "      <td>295.067993</td>\n",
       "      <td>53.135215</td>\n",
       "      <td>2.867831</td>\n",
       "      <td>138.864472</td>\n",
       "      <td>4.534076</td>\n",
       "      <td>11.671064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.610751</td>\n",
       "      <td>0.489448</td>\n",
       "      <td>0.342997</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>-0.352696</td>\n",
       "      <td>-0.352696</td>\n",
       "      <td>0.29277</td>\n",
       "      <td>0.483602</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.445195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>59.513186</td>\n",
       "      <td>88.969977</td>\n",
       "      <td>1.059716</td>\n",
       "      <td>0.364096</td>\n",
       "      <td>105.584697</td>\n",
       "      <td>53.135215</td>\n",
       "      <td>2.452040</td>\n",
       "      <td>136.149336</td>\n",
       "      <td>4.919513</td>\n",
       "      <td>11.608048</td>\n",
       "      <td>...</td>\n",
       "      <td>2.569047</td>\n",
       "      <td>0.489448</td>\n",
       "      <td>0.342997</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.739264</td>\n",
       "      <td>0.739264</td>\n",
       "      <td>0.29277</td>\n",
       "      <td>0.483602</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.445195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>349</td>\n",
       "      <td>69.839398</td>\n",
       "      <td>70.508421</td>\n",
       "      <td>0.683843</td>\n",
       "      <td>0.364096</td>\n",
       "      <td>81.899285</td>\n",
       "      <td>18.798845</td>\n",
       "      <td>1.204667</td>\n",
       "      <td>144.294745</td>\n",
       "      <td>4.809388</td>\n",
       "      <td>13.876642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.610751</td>\n",
       "      <td>0.489448</td>\n",
       "      <td>0.342997</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.739264</td>\n",
       "      <td>0.739264</td>\n",
       "      <td>0.29277</td>\n",
       "      <td>0.483602</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.445195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>50.125720</td>\n",
       "      <td>79.739199</td>\n",
       "      <td>0.683843</td>\n",
       "      <td>0.364096</td>\n",
       "      <td>137.165246</td>\n",
       "      <td>46.267941</td>\n",
       "      <td>1.204667</td>\n",
       "      <td>138.864472</td>\n",
       "      <td>4.809388</td>\n",
       "      <td>13.498543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.610751</td>\n",
       "      <td>0.489448</td>\n",
       "      <td>0.342997</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.739264</td>\n",
       "      <td>0.739264</td>\n",
       "      <td>0.29277</td>\n",
       "      <td>0.483602</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.445195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>48.248227</td>\n",
       "      <td>98.200756</td>\n",
       "      <td>0.683843</td>\n",
       "      <td>0.364096</td>\n",
       "      <td>103.610913</td>\n",
       "      <td>78.642232</td>\n",
       "      <td>4.946786</td>\n",
       "      <td>135.244290</td>\n",
       "      <td>5.525200</td>\n",
       "      <td>8.583255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.610751</td>\n",
       "      <td>0.489448</td>\n",
       "      <td>0.342997</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>-0.352696</td>\n",
       "      <td>0.739264</td>\n",
       "      <td>-2.41565</td>\n",
       "      <td>1.936492</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.445195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>392</td>\n",
       "      <td>51.526619</td>\n",
       "      <td>61.277642</td>\n",
       "      <td>1.247653</td>\n",
       "      <td>0.364096</td>\n",
       "      <td>148.132259</td>\n",
       "      <td>34.495471</td>\n",
       "      <td>1.537300</td>\n",
       "      <td>137.532928</td>\n",
       "      <td>4.604140</td>\n",
       "      <td>11.418998</td>\n",
       "      <td>...</td>\n",
       "      <td>2.569047</td>\n",
       "      <td>1.958664</td>\n",
       "      <td>0.342997</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.739264</td>\n",
       "      <td>0.739264</td>\n",
       "      <td>0.29277</td>\n",
       "      <td>0.483602</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.445195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>35.105775</td>\n",
       "      <td>61.277642</td>\n",
       "      <td>0.683843</td>\n",
       "      <td>0.364096</td>\n",
       "      <td>91.768207</td>\n",
       "      <td>49.211058</td>\n",
       "      <td>1.537300</td>\n",
       "      <td>135.244290</td>\n",
       "      <td>4.534076</td>\n",
       "      <td>13.120444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.610751</td>\n",
       "      <td>0.489448</td>\n",
       "      <td>0.342997</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.739264</td>\n",
       "      <td>0.739264</td>\n",
       "      <td>0.29277</td>\n",
       "      <td>0.483602</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.445195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age         bp        al        su         bgr         bu  \\\n",
       "132  46.370734  70.508421  0.683843  0.364096  100.650236  47.248980   \n",
       "309  65.145665  88.969977  1.059716  0.364096  152.955521  75.699115   \n",
       "334  67.961905  70.508421  0.683843  0.364096   83.873070  42.343784   \n",
       "196  54.819453  98.200756  0.871779  0.328695  295.067993  53.135215   \n",
       "246  59.513186  88.969977  1.059716  0.364096  105.584697  53.135215   \n",
       "..         ...        ...       ...       ...         ...        ...   \n",
       "349  69.839398  70.508421  0.683843  0.364096   81.899285  18.798845   \n",
       "168  50.125720  79.739199  0.683843  0.364096  137.165246  46.267941   \n",
       "150  48.248227  98.200756  0.683843  0.364096  103.610913  78.642232   \n",
       "392  51.526619  61.277642  1.247653  0.364096  148.132259  34.495471   \n",
       "66   35.105775  61.277642  0.683843  0.364096   91.768207  49.211058   \n",
       "\n",
       "           sc         sod       pot       hrmo  ...  rbc_normal  pc_normal  \\\n",
       "132  0.955193  141.579608  3.983452  14.947923  ...    0.610751   0.489448   \n",
       "309  3.283622  137.532928  4.604140  12.501720  ...    0.610751   0.489448   \n",
       "334  1.537300  138.864472  4.093577  14.821890  ...    0.610751   0.489448   \n",
       "196  2.867831  138.864472  4.534076  11.671064  ...    0.610751   0.489448   \n",
       "246  2.452040  136.149336  4.919513  11.608048  ...    2.569047   0.489448   \n",
       "..        ...         ...       ...        ...  ...         ...        ...   \n",
       "349  1.204667  144.294745  4.809388  13.876642  ...    0.610751   0.489448   \n",
       "168  1.204667  138.864472  4.809388  13.498543  ...    0.610751   0.489448   \n",
       "150  4.946786  135.244290  5.525200   8.583255  ...    0.610751   0.489448   \n",
       "392  1.537300  137.532928  4.604140  11.418998  ...    2.569047   1.958664   \n",
       "66   1.537300  135.244290  4.534076  13.120444  ...    0.610751   0.489448   \n",
       "\n",
       "     pcc_present  ba_present   htn_yes    dm_yes  cad_yes  appet_yes  \\\n",
       "132     0.342997    0.235702  0.739264  0.739264  0.29277   0.483602   \n",
       "309     0.342997   -3.242641  0.739264  0.739264  0.29277   1.936492   \n",
       "334     0.342997    0.235702  0.739264  0.739264  0.29277   0.483602   \n",
       "196     0.342997    0.235702 -0.352696 -0.352696  0.29277   0.483602   \n",
       "246     0.342997    0.235702  0.739264  0.739264  0.29277   0.483602   \n",
       "..           ...         ...       ...       ...      ...        ...   \n",
       "349     0.342997    0.235702  0.739264  0.739264  0.29277   0.483602   \n",
       "168     0.342997    0.235702  0.739264  0.739264  0.29277   0.483602   \n",
       "150     0.342997    0.235702 -0.352696  0.739264 -2.41565   1.936492   \n",
       "392     0.342997    0.235702  0.739264  0.739264  0.29277   0.483602   \n",
       "66      0.342997    0.235702  0.739264  0.739264  0.29277   0.483602   \n",
       "\n",
       "       pe_yes   ane_yes  \n",
       "132  0.522233  0.445195  \n",
       "309  0.522233  0.445195  \n",
       "334  0.522233  0.445195  \n",
       "196  0.522233  0.445195  \n",
       "246  0.522233  0.445195  \n",
       "..        ...       ...  \n",
       "349  0.522233  0.445195  \n",
       "168  0.522233  0.445195  \n",
       "150  0.522233  0.445195  \n",
       "392  0.522233  0.445195  \n",
       "66   0.522233  0.445195  \n",
       "\n",
       "[133 rows x 27 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert the data into standardized data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test-sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:926: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [10, 100]},\n",
       "             scoring='f1', verbose=3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "param_grid = {'criterion':['gini', 'entropy'],'max_features':['auto', 'sqrt', 'log2'], 'n_estimators':[10, 100]}\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid, refit=True, verbose=3, n_jobs=-1, scoring='f1')\n",
    "#Here, refit=True is used to store best model in 'grid' among all the combinations\n",
    "#Here, scoring='f1_weighted' is used. Because, its suitable for balanced and imbalanced data as well as precision, recall etc.,\n",
    "#fitting the model for grid search\n",
    "grid.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value for best parameter {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100}:\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning. Format is print(grid.best_params_)\n",
    "print(\"The value for best parameter {}:\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.124996</td>\n",
       "      <td>5.321627e-02</td>\n",
       "      <td>0.012499</td>\n",
       "      <td>6.249619e-03</td>\n",
       "      <td>gini</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'auto', ...</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966091</td>\n",
       "      <td>0.021345</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.465608</td>\n",
       "      <td>1.822298e-02</td>\n",
       "      <td>0.056248</td>\n",
       "      <td>7.654441e-03</td>\n",
       "      <td>gini</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'auto', ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.982066</td>\n",
       "      <td>0.011227</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.068748</td>\n",
       "      <td>7.653916e-03</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>1.328315e-06</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'sqrt', ...</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.973024</td>\n",
       "      <td>0.010882</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.474983</td>\n",
       "      <td>2.898051e-02</td>\n",
       "      <td>0.056248</td>\n",
       "      <td>7.654636e-03</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'sqrt', ...</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.976442</td>\n",
       "      <td>0.011053</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.068748</td>\n",
       "      <td>7.654247e-03</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>6.249952e-03</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'log2', ...</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.976005</td>\n",
       "      <td>0.007455</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.474984</td>\n",
       "      <td>1.593386e-02</td>\n",
       "      <td>0.056248</td>\n",
       "      <td>7.654675e-03</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'log2', ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982412</td>\n",
       "      <td>0.016695</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.071874</td>\n",
       "      <td>7.655376e-03</td>\n",
       "      <td>0.012498</td>\n",
       "      <td>6.249047e-03</td>\n",
       "      <td>entropy</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'auto...</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.976005</td>\n",
       "      <td>0.007455</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.484356</td>\n",
       "      <td>2.420470e-02</td>\n",
       "      <td>0.056249</td>\n",
       "      <td>7.653916e-03</td>\n",
       "      <td>entropy</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'auto...</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979329</td>\n",
       "      <td>0.014636</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.065622</td>\n",
       "      <td>6.249762e-03</td>\n",
       "      <td>0.015624</td>\n",
       "      <td>1.548069e-06</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'sqrt...</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.969561</td>\n",
       "      <td>0.014331</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.496857</td>\n",
       "      <td>3.479796e-02</td>\n",
       "      <td>0.056249</td>\n",
       "      <td>7.655045e-03</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'sqrt...</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976254</td>\n",
       "      <td>0.014721</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.062498</td>\n",
       "      <td>5.001110e-07</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>6.743496e-07</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'log2...</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982601</td>\n",
       "      <td>0.020963</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.437485</td>\n",
       "      <td>7.125751e-02</td>\n",
       "      <td>0.046874</td>\n",
       "      <td>1.397532e-02</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'log2...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985148</td>\n",
       "      <td>0.013179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.124996  5.321627e-02         0.012499    6.249619e-03   \n",
       "1        0.465608  1.822298e-02         0.056248    7.654441e-03   \n",
       "2        0.068748  7.653916e-03         0.015625    1.328315e-06   \n",
       "3        0.474983  2.898051e-02         0.056248    7.654636e-03   \n",
       "4        0.068748  7.654247e-03         0.012500    6.249952e-03   \n",
       "5        0.474984  1.593386e-02         0.056248    7.654675e-03   \n",
       "6        0.071874  7.655376e-03         0.012498    6.249047e-03   \n",
       "7        0.484356  2.420470e-02         0.056249    7.653916e-03   \n",
       "8        0.065622  6.249762e-03         0.015624    1.548069e-06   \n",
       "9        0.496857  3.479796e-02         0.056249    7.655045e-03   \n",
       "10       0.062498  5.001110e-07         0.015625    6.743496e-07   \n",
       "11       0.437485  7.125751e-02         0.046874    1.397532e-02   \n",
       "\n",
       "   param_criterion param_max_features param_n_estimators  \\\n",
       "0             gini               auto                 10   \n",
       "1             gini               auto                100   \n",
       "2             gini               sqrt                 10   \n",
       "3             gini               sqrt                100   \n",
       "4             gini               log2                 10   \n",
       "5             gini               log2                100   \n",
       "6          entropy               auto                 10   \n",
       "7          entropy               auto                100   \n",
       "8          entropy               sqrt                 10   \n",
       "9          entropy               sqrt                100   \n",
       "10         entropy               log2                 10   \n",
       "11         entropy               log2                100   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'criterion': 'gini', 'max_features': 'auto', ...           0.953846   \n",
       "1   {'criterion': 'gini', 'max_features': 'auto', ...           1.000000   \n",
       "2   {'criterion': 'gini', 'max_features': 'sqrt', ...           0.985075   \n",
       "3   {'criterion': 'gini', 'max_features': 'sqrt', ...           0.985075   \n",
       "4   {'criterion': 'gini', 'max_features': 'log2', ...           0.985075   \n",
       "5   {'criterion': 'gini', 'max_features': 'log2', ...           1.000000   \n",
       "6   {'criterion': 'entropy', 'max_features': 'auto...           0.985075   \n",
       "7   {'criterion': 'entropy', 'max_features': 'auto...           0.985075   \n",
       "8   {'criterion': 'entropy', 'max_features': 'sqrt...           0.953846   \n",
       "9   {'criterion': 'entropy', 'max_features': 'sqrt...           0.985075   \n",
       "10  {'criterion': 'entropy', 'max_features': 'log2...           0.985075   \n",
       "11  {'criterion': 'entropy', 'max_features': 'log2...           1.000000   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.971429           0.935484           0.969697   \n",
       "1            0.971429           0.968750           0.985075   \n",
       "2            0.956522           0.968750           0.969697   \n",
       "3            0.957746           0.984615           0.969697   \n",
       "4            0.971429           0.968750           0.969697   \n",
       "5            0.957746           0.984615           0.969697   \n",
       "6            0.971429           0.968750           0.969697   \n",
       "7            0.957746           0.968750           0.985075   \n",
       "8            0.971429           0.952381           0.985075   \n",
       "9            0.957746           0.968750           0.969697   \n",
       "10           0.942857           1.000000           0.985075   \n",
       "11           0.971429           0.984615           0.969697   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            1.000000         0.966091        0.021345               12  \n",
       "1            0.985075         0.982066        0.011227                4  \n",
       "2            0.985075         0.973024        0.010882               10  \n",
       "3            0.985075         0.976442        0.011053                6  \n",
       "4            0.985075         0.976005        0.007455                8  \n",
       "5            1.000000         0.982412        0.016695                3  \n",
       "6            0.985075         0.976005        0.007455                8  \n",
       "7            1.000000         0.979329        0.014636                5  \n",
       "8            0.985075         0.969561        0.014331               11  \n",
       "9            1.000000         0.976254        0.014721                7  \n",
       "10           1.000000         0.982601        0.020963                2  \n",
       "11           1.000000         0.985148        0.013179                1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=grid.cv_results_\n",
    "#to view entire result table\n",
    "table=pd.DataFrame.from_dict(result)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "y_pred=grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 51],\n",
       "       [ 0, 82]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix#instead of r2_score we use confusion_matrix here\n",
    "cm=confusion_matrix(Y_test,y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "clf_report=classification_report(Y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        51\n",
      "           1       0.62      1.00      0.76        82\n",
      "\n",
      "    accuracy                           0.62       133\n",
      "   macro avg       0.31      0.50      0.38       133\n",
      "weighted avg       0.38      0.62      0.47       133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Future_Prediction={}\".format(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
